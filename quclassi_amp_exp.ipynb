{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3275f0-77fb-4b5d-83fc-0ab62e99b762",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0d8db246-15b6-4254-af4b-b796c13d2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from qiskit import QuantumRegister, ClassicalRegister\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit import Aer, execute\n",
    "from math import pi,log\n",
    "from qiskit import *\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from qiskit import Aer, IBMQ\n",
    "import os\n",
    "from datetime import datetime\n",
    "from qiskit.extensions import UnitaryGate\n",
    "import scipy\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347631a-5ad7-4d1f-b8aa-cf54c64f51aa",
   "metadata": {},
   "source": [
    "#### Running and Saving Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0fe356ce-9551-4092-8cfc-e65c5d462377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network saving and loading\n",
    "epoch = 25\n",
    "runtime_name = datetime.now().strftime(\"Date-%d%m%y--Hours-%H%M\")\n",
    "runtime_name += \"-epoch-{}\".format(epoch)\n",
    "os.mkdir(runtime_name)\n",
    "backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7272c0a-cb8a-4145-8c1c-a5dc86eb99a7",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df9fde07-43d9-41bc-bdf7-d8c4b3ffe6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample to SUBSAMPLE datapoints. This is due to computational cost.\n",
    "# Chance SUBSAMPLE to what best suits your computer, to make a reasonable training time.\n",
    "test_images,test_labels = tf.keras.datasets.mnist.load_data()\n",
    "train_images = test_images[0].reshape(60000,784)\n",
    "train_labels = test_images[1]\n",
    "labels = test_images[1]\n",
    "train_images = train_images/255\n",
    "k=4\n",
    "pca = PCA(n_components=k)\n",
    "pca.fit(train_images)\n",
    "\n",
    "# Computational cost is high for 60,000 data points. Change 6000 to what your system can handle\n",
    "SUBSAMPLE = 1000\n",
    "pca_data = pca.transform(train_images)[:SUBSAMPLE]\n",
    "train_labels = train_labels[:SUBSAMPLE]\n",
    "t_pca_data = pca_data.copy()\n",
    "pca_descaler = [[] for _ in range(k)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce180a4-aba3-4a32-94aa-b9263de290d4",
   "metadata": {},
   "source": [
    "### <font color='green'> Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc258c18-80bc-4059-9860-87814d77f725",
   "metadata": {},
   "source": [
    "<font color='green'> Changes made: no rotations or squaring before filtering out unused data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0308c017-b195-464c-b00f-f53b830e1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation Section\n",
    "for i in range(k):\n",
    "    if pca_data[:,i].min() < 0:\n",
    "        pca_descaler[i].append(pca_data[:,i].min())\n",
    "        pca_data[:,i] += np.abs(pca_data[:,i].min())\n",
    "    else:\n",
    "        pca_descaler[i].append(pca_data[:,i].min())\n",
    "        pca_data[:,i] -= pca_data[:,i].min()\n",
    "    pca_descaler[i].append(pca_data[:,i].max())\n",
    "    pca_data[:,i] /= pca_data[:,i].max()\n",
    "\n",
    "#CHANGE\n",
    "# pca_data_rot= np.sqrt(pca_data)\n",
    "pca_data_rot= pca_data\n",
    "\n",
    "valid_labels = None\n",
    "valid_labels = train_labels==3\n",
    "valid_labels += train_labels == 6\n",
    "\n",
    "for col in range(pca_data.shape[1]):\n",
    "    t_data_mean = pca_data[:,col].mean()\n",
    "    t_data_std = pca_data[:,col].std()\n",
    "    valid_upper_bound = pca_data[:,col] < t_data_mean+t_data_std\n",
    "    valid_lower_bound = pca_data[:,col] > t_data_mean-t_data_std\n",
    "    valid = np.logical_and(valid_upper_bound,valid_lower_bound)\n",
    "    pca_data = pca_data[valid]\n",
    "\n",
    "pca_data_rot3 = pca_data_rot[train_labels==3]\n",
    "pca_data_rot6 = pca_data_rot[train_labels==6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece1d78-92d2-43f6-8e0d-6562bfe3703e",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e1b70284-5cea-46d7-af48-3d007413f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointing code\n",
    "def save_variables(var_dict, epoch, number_class):\n",
    "    with open(f\"{runtime_name}/Epoch-{epoch}-Variables-numbers-{number_class}\", 'w') as file:\n",
    "        file.write(str(var_dict))\n",
    "\n",
    "# Ran_ang returns a random angle\n",
    "def ran_ang():\n",
    "    return np.random.rand() * 2 * np.pi\n",
    "\n",
    "\n",
    "def single_qubit_unitary(circ_ident, qubit_index, values):\n",
    "    circ_ident.ry(values[0], qubit_index)\n",
    "    circ_ident.rz(values[1], qubit_index)\n",
    "\n",
    "\n",
    "def dual_qubit_unitary(circ_ident, qubit_1, qubit_2, values):\n",
    "    circ_ident.ryy(values[0], qubit_1, qubit_2)\n",
    "    circ_ident.rzz(values[1], qubit_1, qubit_2)\n",
    "\n",
    "\n",
    "def controlled_dual_qubit_unitary(circ_ident, control_qubit, act_qubit, values):\n",
    "    circ_ident.cry(values[0], control_qubit, act_qubit)\n",
    "    circ_ident.crz(values[1], control_qubit, act_qubit)\n",
    "\n",
    "\n",
    "def traditional_learning_layer(circ_ident, num_qubits, values, style=\"Dual\", qubit_start=1, qubit_end=5):\n",
    "    if style == \"Dual\":\n",
    "        for qub in np.arange(qubit_start, qubit_end):\n",
    "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
    "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
    "            dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \",\" + str(qub + 1)])\n",
    "    elif style == \"Single\":\n",
    "        for qub in np.arange(qubit_start, qubit_end):\n",
    "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
    "    elif style == \"Controlled-Dual\":\n",
    "        for qub in np.arange(qubit_start, qubit_end):\n",
    "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
    "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
    "            dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \",\" + str(qub + 1)])\n",
    "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
    "            controlled_dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \"--\" + str(qub + 1)])\n",
    "\n",
    "\n",
    "def swap_test(circ_ident, num_qubits):\n",
    "    num_swap = num_qubits // 2\n",
    "    for i in range(num_swap):\n",
    "        circ_ident.cswap(0, i + 1, i + num_swap + 1)\n",
    "    circ_ident.h(0)\n",
    "    circ_ident.measure(0, 0)\n",
    "\n",
    "\n",
    "def init_random_variables(q, style):\n",
    "    trainable_variables = {}\n",
    "    if style == \"Single\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
    "    elif style == \"Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
    "    elif style == \"Controlled-Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
    "                trainable_variables[str(i) + \"--\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
    "    return trainable_variables\n",
    "\n",
    "\n",
    "def init_gradient_variables(q, style):\n",
    "    trainable_variables = {}\n",
    "    if style == \"Single\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [[], []]\n",
    "    elif style == \"Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [[], []]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [[], []]\n",
    "    elif style == \"Controlled-Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [0, 0]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [[], []]\n",
    "                trainable_variables[str(i) + \"--\" + str(i + 1)] = [[], []]\n",
    "    return trainable_variables\n",
    "\n",
    "\n",
    "def get_probabilities(circ, count=10000, inducing=False):\n",
    "    if inducing == True:\n",
    "        count *= 10\n",
    "    job = execute(circ, backend, shots=count)\n",
    "    results = job.result().get_counts(circ)\n",
    "    try:\n",
    "        prob = results['0'] / (results['1'] + results['0'])\n",
    "        prob = (prob - 0.5)\n",
    "        if prob <= 0:\n",
    "            prob = 1e-16\n",
    "        else:\n",
    "            prob = prob * 2\n",
    "    except:\n",
    "        prob = 1\n",
    "    return prob\n",
    "\n",
    "\n",
    "\n",
    "# Define loss function. SWAP Test returns probability, so minmax probability is logical\n",
    "def cost_function(p, yreal):\n",
    "    if yreal == 1:\n",
    "        return -np.log(p)\n",
    "    else:\n",
    "        return -np.log(1 - p)\n",
    "\n",
    "\n",
    "def update_weights(init_value, lr, grad):\n",
    "    while lr * grad > 2 * np.pi:\n",
    "        lr /= 10\n",
    "        print(\"Warning - Gradient taking steps that are very large. Drop learning rate\")\n",
    "    weight_update = lr * grad\n",
    "    new_value = init_value\n",
    "    if new_value - weight_update > 2 * np.pi:\n",
    "        new_value = (new_value - weight_update) - 2 * np.pi\n",
    "    elif new_value - weight_update < 0:\n",
    "        new_value = (new_value - weight_update) + 2 * np.pi\n",
    "    else:\n",
    "        new_value = new_value - weight_update\n",
    "    return new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55421af-fa1d-49c1-87bc-a828506b5e9d",
   "metadata": {},
   "source": [
    "### <font color='green'> Encode Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35910da-c633-4605-acda-a87b8e3f83a4",
   "metadata": {},
   "source": [
    "<font color='green'>Fully changed</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "42086ed7-f926-405c-9937-d964101d7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_circuit(circ_ident, num_qubits, values, qubit_start=1, qubit_end=5):\n",
    "    #normalize the vector \n",
    "    values_sq = np.square(values)\n",
    "    norm = np.linalg.norm(values_sq)\n",
    "    values_norm = values_sq / norm\n",
    "\n",
    "    #print(values_norm, values_norm[0]**2 + values_norm[1]**2 + values_norm[2]**2 + values_norm[3]**2) \n",
    "    \n",
    "    #create a matrix where the first column has the data\n",
    "    mat = np.zeros((len(values_norm),len(values_norm)))\n",
    "    mat[:,0] = values_norm\n",
    "\n",
    "    #get the unitary matrix through singular value decomposition\n",
    "    u, s, v = scipy.linalg.svd(mat)\n",
    "    instruction = UnitaryGate(u)\n",
    "\n",
    "    # print(u)\n",
    "    \n",
    "    #append the instruction to the circuit (last 2 qubits)\n",
    "    circ_ident.append(instruction,[3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1195f8-6c5b-4e76-beae-f6e544908baf",
   "metadata": {},
   "source": [
    "#### Discriminator Training Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e39a798e-8454-430b-8fa3-dccbe3c03235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# We treat the first n qubits are the discriminators state. n is always defined as the\n",
    "# integer division floor of the qubit count.\n",
    "# This is due to the fact that a state will always be k qubits, therefore the\n",
    "# number of total qubits must be 2k+1. 2k as we need k for the disc, and k to represent\n",
    "# either the other learned quantum state, or k to represent a data point\n",
    "# then +1 to perform the SWAP test. Therefore, we know that we will always end up\n",
    "# with an odd number of qubits. We take the floor to solve for k. 1st k represents\n",
    "# disc, 2nd k represents the \"loaded\" state be it gen or real data\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Use different function calls to represent training a GENERATOR or training a DISCRIMINATOR\n",
    "# ------------------------------------------------------------------------------------\n",
    "def disc_real_training_circuit(training_variables, data, key=None, key_value=None, diff=False, fwd_diff=False):\n",
    "    circ = QuantumCircuit(q, c)\n",
    "    circ.h(0)\n",
    "    if diff == True and fwd_diff == True:\n",
    "        training_variables[key][key_value] += par_shift\n",
    "    if diff == True and fwd_diff == False:\n",
    "        training_variables[key][key_value] -= par_shift\n",
    "    traditional_learning_layer(circ, q, training_variables, style=layer_style, qubit_start=1, qubit_end=q // 2 + 1)\n",
    "    data_loading_circuit(circ, q, data, qubit_start=q // 2 + 1, qubit_end=q)  \n",
    "    swap_test(circ, q)\n",
    "    if diff == True and fwd_diff == True:\n",
    "        training_variables[key][key_value] -= par_shift\n",
    "    if diff == True and fwd_diff == False:\n",
    "        training_variables[key][key_value] += par_shift\n",
    "    return circ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be03d2-e3a4-4bc9-a51f-9e5d1b5db8f2",
   "metadata": {},
   "source": [
    "#### Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "786c6109-aef7-4c2f-b52e-2903ebdcc404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "--------------------\n",
      "train_var_0 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mg/bkddtr0n1pdgnjysfjbpr5380000gn/T/ipykernel_91121/15459503.py:113: RuntimeWarning: invalid value encountered in log\n",
      "  return -np.log(1 - p)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key_value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(value)):\n\u001b[0;32m---> 42\u001b[0m     forward_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(get_probabilities(\n\u001b[1;32m     43\u001b[0m         disc_real_training_circuit(train_var_0, point, key, key_value, diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fwd_diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)))\n\u001b[1;32m     44\u001b[0m     backward_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(get_probabilities(\n\u001b[1;32m     45\u001b[0m         disc_real_training_circuit(train_var_0, point, key, key_value, diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fwd_diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)))\n\u001b[1;32m     46\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (forward_diff \u001b[38;5;241m-\u001b[39m backward_diff)\n",
      "Cell \u001b[0;32mIn[90], line 94\u001b[0m, in \u001b[0;36mget_probabilities\u001b[0;34m(circ, count, inducing)\u001b[0m\n\u001b[1;32m     92\u001b[0m     count \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     93\u001b[0m job \u001b[38;5;241m=\u001b[39m execute(circ, backend, shots\u001b[38;5;241m=\u001b[39mcount)\n\u001b[0;32m---> 94\u001b[0m results \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mget_counts(circ)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     prob \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m (results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/qiskit_aer/jobs/utils.py:42\u001b[0m, in \u001b[0;36mrequires_submit.<locals>._wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_future \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JobError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob not submitted yet!. You have to .submit() first!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/qiskit_aer/jobs/aerjob.py:114\u001b[0m, in \u001b[0;36mAerJob.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@requires_submit\u001b[39m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# pylint: disable=arguments-differ\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get job result. The behavior is the same as the underlying\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    concurrent Future objects,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m        concurrent.futures.CancelledError: if job cancelled before completed.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------------\n",
    "# THIS SECTION WE DO THE TUNING FOR WHAT WE KNOW WE WANT TO BE CHANGING!\n",
    "# ------------------------------------------------------------------------------------------\n",
    "\n",
    "q = 5  # Number of qubits = Dimensionality of data = round up to even number = num qubits\n",
    "c = 1\n",
    "circ = QuantumCircuit(q, c)\n",
    "circ.h(0)\n",
    "layer_style = \"Dual\"\n",
    "train_var_0 = init_random_variables(q // 2, layer_style)\n",
    "train_var_1 = init_random_variables(q // 2, layer_style)\n",
    "train_var_2 = init_random_variables(q // 2, layer_style)\n",
    "\n",
    "tracked_d_loss = []\n",
    "tracked_d_loss1 = []\n",
    "tracked_d_loss2 = []\n",
    "gradients = []\n",
    "learning_rate = 0.01\n",
    "train_iter = 5\n",
    "corr = 0\n",
    "wrong = 0\n",
    "loss_d_to_real = 0\n",
    "print('Starting Training')\n",
    "print('-' * 20)\n",
    "print(\"train_var_0 training\")\n",
    "for epoch in range(train_iter):\n",
    "    start = time.time()\n",
    "    # loss = [0, 0]\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    \n",
    "    par_shift = 0.5 * np.pi / ((1 + epoch) ** 0.5)\n",
    "    for index, point in enumerate(pca_data_rot3):\n",
    "\n",
    "        loss = 0\n",
    "        \n",
    "        for key, value in train_var_0.items():\n",
    "            if str(q // 2 + 1) in key:\n",
    "                break\n",
    "            for key_value in range(len(value)):\n",
    "                forward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_0, point, key, key_value, diff=True, fwd_diff=True)))\n",
    "                backward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_0, point, key, key_value, diff=True, fwd_diff=False)))\n",
    "                df = 0.5 * (forward_diff - backward_diff)\n",
    "                train_var_0[key][key_value] -= df * learning_rate\n",
    "\n",
    "                cf = cost_function(df, 0)\n",
    "                if (np.isnan(cf)):\n",
    "                    loss += 1\n",
    "                else:\n",
    "                    loss += cf\n",
    "\n",
    "        epoch_loss += loss\n",
    "        count += 1\n",
    "\n",
    "    avg_loss = epoch_loss / count\n",
    "    tracked_d_loss.append(avg_loss)\n",
    "    print(epoch_loss, avg_loss)\n",
    "        \n",
    "    print('Time for Epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "    print(\"-\" * 20)\n",
    "    save_variables(train_var_0, epoch, 3)\n",
    "\n",
    "for epoch in range(train_iter):\n",
    "    start = time.time()\n",
    "    # loss = [0, 0]\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    \n",
    "    par_shift = 0.5 * np.pi / ((1 + epoch) ** 0.5)\n",
    "    for index, point in enumerate(pca_data_rot6):\n",
    "        loss = 0\n",
    "        \n",
    "        for key, value in train_var_1.items():\n",
    "            if str(q // 2 + 1) in key:\n",
    "                break\n",
    "            for key_value in range(len(value)):\n",
    "                forward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_1, point, key, key_value, diff=True, fwd_diff=True)))\n",
    "                backward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_1, point, key, key_value, diff=True, fwd_diff=False)))\n",
    "                df = 0.5 * (forward_diff - backward_diff)\n",
    "                train_var_1[key][key_value] -= df * learning_rate\n",
    "\n",
    "                cf = cost_function(df, 1)\n",
    "                print(cf)\n",
    "                if (np.isnan(cf)):\n",
    "                    print(\"eh\")\n",
    "                    loss += 1\n",
    "                else:\n",
    "                    loss += cf\n",
    "\n",
    "        epoch_loss += loss\n",
    "        count += 1\n",
    "    \n",
    "    avg_loss = epoch_loss / count\n",
    "    tracked_d_loss.append(avg_loss)\n",
    "    print(epoch_loss, avg_loss)\n",
    "    \n",
    "    print('Time for Epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "    print(\"-\" * 20)\n",
    "    save_variables(train_var_1, epoch, 6)\n",
    "\n",
    "#CHANGE PCA_DATA_ROT VARS HERE\n",
    "pca_data = []\n",
    "[pca_data.append(x) for x in pca_data_rot3]\n",
    "[pca_data.append(x) for x in pca_data_rot6]\n",
    "labels = []\n",
    "[labels.append(0) for _ in range(len(pca_data_rot3))]\n",
    "[labels.append(1) for _ in range(len(pca_data_rot6))]\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "ones = []\n",
    "zeros = []\n",
    "layer_style = 'Dual'\n",
    "\n",
    "ones_predicted = 0\n",
    "zeros_predicted = 0\n",
    "\n",
    "p0_vals = []\n",
    "p1_vals = []\n",
    "\n",
    "for index, x in enumerate(pca_data):\n",
    "    p0 = get_probabilities(disc_real_training_circuit(train_var_0, x, None, None, diff=False, fwd_diff=False))\n",
    "    p1 = get_probabilities(disc_real_training_circuit(train_var_1, x, None, None, diff=False, fwd_diff=False))\n",
    "    tp = p0 + p1\n",
    "    p0 = p0 / tp\n",
    "    p1 = p1 / tp\n",
    "    probs = np.array([p0, p1])\n",
    "    if np.argmax(probs) == labels[index]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "\n",
    "    if np.argmax(probs) == 1:\n",
    "        ones_predicted += 1\n",
    "    else:\n",
    "        zeros_predicted += 1\n",
    "        \n",
    "    p0_vals.append(p0)\n",
    "    p1_vals.append(p1)\n",
    "\n",
    "entropies = entropy([np.array(p0_vals), np.array(p1_vals)], base = 2, axis = 0)\n",
    "avg_ent = np.mean(entropies)\n",
    "\n",
    "plt.plot(tracked_d_loss)\n",
    "plt.show()\n",
    "\n",
    "print(\"Ones predicted\", ones_predicted, \"Zeros predicted\", zeros_predicted)\n",
    "print(f\"Accuracy {correct / (correct + wrong)}\")\n",
    "print(\"Average entropy\", avg_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f215e62-bffd-4626-a154-b176b64725d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
