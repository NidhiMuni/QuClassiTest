{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3275f0-77fb-4b5d-83fc-0ab62e99b762",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d8db246-15b6-4254-af4b-b796c13d2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from qiskit import QuantumRegister, ClassicalRegister\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit import Aer, execute\n",
    "from math import pi,log\n",
    "from qiskit import *\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from qiskit import Aer, IBMQ\n",
    "import os\n",
    "from datetime import datetime\n",
    "from qiskit.extensions import UnitaryGate\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347631a-5ad7-4d1f-b8aa-cf54c64f51aa",
   "metadata": {},
   "source": [
    "#### Running and Saving Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fe356ce-9551-4092-8cfc-e65c5d462377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network saving and loading\n",
    "epoch = 25\n",
    "runtime_name = datetime.now().strftime(\"Date-%d%m%y--Hours-%H%M\")\n",
    "runtime_name += \"-epoch-{}\".format(epoch)\n",
    "os.mkdir(runtime_name)\n",
    "backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7272c0a-cb8a-4145-8c1c-a5dc86eb99a7",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df9fde07-43d9-41bc-bdf7-d8c4b3ffe6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample to SUBSAMPLE datapoints. This is due to computational cost.\n",
    "# Chance SUBSAMPLE to what best suits your computer, to make a reasonable training time.\n",
    "test_images,test_labels = tf.keras.datasets.mnist.load_data()\n",
    "train_images = test_images[0].reshape(60000,784)\n",
    "train_labels = test_images[1]\n",
    "labels = test_images[1]\n",
    "train_images = train_images/255\n",
    "k=4\n",
    "pca = PCA(n_components=k)\n",
    "pca.fit(train_images)\n",
    "\n",
    "# Computational cost is high for 60,000 data points. Change 6000 to what your system can handle\n",
    "SUBSAMPLE = 1000\n",
    "pca_data = pca.transform(train_images)[:SUBSAMPLE]\n",
    "train_labels = train_labels[:SUBSAMPLE]\n",
    "t_pca_data = pca_data.copy()\n",
    "pca_descaler = [[] for _ in range(k)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce180a4-aba3-4a32-94aa-b9263de290d4",
   "metadata": {},
   "source": [
    "### <font color='green'> Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc258c18-80bc-4059-9860-87814d77f725",
   "metadata": {},
   "source": [
    "<font color='green'> Changes made: no rotations or squaring before filtering out unused data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0308c017-b195-464c-b00f-f53b830e1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation Section\n",
    "for i in range(k):\n",
    "    if pca_data[:,i].min() < 0:\n",
    "        pca_descaler[i].append(pca_data[:,i].min())\n",
    "        pca_data[:,i] += np.abs(pca_data[:,i].min())\n",
    "    else:\n",
    "        pca_descaler[i].append(pca_data[:,i].min())\n",
    "        pca_data[:,i] -= pca_data[:,i].min()\n",
    "    pca_descaler[i].append(pca_data[:,i].max())\n",
    "    pca_data[:,i] /= pca_data[:,i].max()\n",
    "\n",
    "#CHANGE\n",
    "# pca_data_rot= np.sqrt(pca_data)\n",
    "pca_data_rot= pca_data\n",
    "\n",
    "valid_labels = None\n",
    "valid_labels = train_labels==3\n",
    "valid_labels += train_labels == 6\n",
    "\n",
    "for col in range(pca_data.shape[1]):\n",
    "    t_data_mean = pca_data[:,col].mean()\n",
    "    t_data_std = pca_data[:,col].std()\n",
    "    valid_upper_bound = pca_data[:,col] < t_data_mean+t_data_std\n",
    "    valid_lower_bound = pca_data[:,col] > t_data_mean-t_data_std\n",
    "    valid = np.logical_and(valid_upper_bound,valid_lower_bound)\n",
    "    pca_data = pca_data[valid]\n",
    "\n",
    "pca_data_rot3 = pca_data_rot[train_labels==3]\n",
    "pca_data_rot6 = pca_data_rot[train_labels==6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece1d78-92d2-43f6-8e0d-6562bfe3703e",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1b70284-5cea-46d7-af48-3d007413f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointing code\n",
    "def save_variables(var_dict, epoch, number_class):\n",
    "    with open(f\"{runtime_name}/Epoch-{epoch}-Variables-numbers-{number_class}\", 'w') as file:\n",
    "        file.write(str(var_dict))\n",
    "\n",
    "# Ran_ang returns a random angle\n",
    "def ran_ang():\n",
    "    return np.random.rand() * 2 * np.pi\n",
    "\n",
    "\n",
    "def single_qubit_unitary(circ_ident, qubit_index, values):\n",
    "    circ_ident.ry(values[0], qubit_index)\n",
    "    circ_ident.rz(values[1], qubit_index)\n",
    "\n",
    "\n",
    "def dual_qubit_unitary(circ_ident, qubit_1, qubit_2, values):\n",
    "    circ_ident.ryy(values[0], qubit_1, qubit_2)\n",
    "    circ_ident.rzz(values[1], qubit_1, qubit_2)\n",
    "\n",
    "\n",
    "def controlled_dual_qubit_unitary(circ_ident, control_qubit, act_qubit, values):\n",
    "    circ_ident.cry(values[0], control_qubit, act_qubit)\n",
    "    circ_ident.crz(values[1], control_qubit, act_qubit)\n",
    "\n",
    "\n",
    "def traditional_learning_layer(circ_ident, num_qubits, values, style=\"Dual\", qubit_start=1, qubit_end=5):\n",
    "    if style == \"Dual\":\n",
    "        for qub in np.arange(qubit_start, qubit_end):\n",
    "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
    "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
    "            dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \",\" + str(qub + 1)])\n",
    "    elif style == \"Single\":\n",
    "        for qub in np.arange(qubit_start, qubit_end):\n",
    "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
    "    elif style == \"Controlled-Dual\":\n",
    "        for qub in np.arange(qubit_start, qubit_end):\n",
    "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
    "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
    "            dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \",\" + str(qub + 1)])\n",
    "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
    "            controlled_dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \"--\" + str(qub + 1)])\n",
    "\n",
    "\n",
    "def swap_test(circ_ident, num_qubits):\n",
    "    num_swap = num_qubits // 2\n",
    "    for i in range(num_swap):\n",
    "        circ_ident.cswap(0, i + 1, i + num_swap + 1)\n",
    "    circ_ident.h(0)\n",
    "    circ_ident.measure(0, 0)\n",
    "\n",
    "\n",
    "def init_random_variables(q, style):\n",
    "    trainable_variables = {}\n",
    "    if style == \"Single\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
    "    elif style == \"Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
    "    elif style == \"Controlled-Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
    "                trainable_variables[str(i) + \"--\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
    "    return trainable_variables\n",
    "\n",
    "\n",
    "def init_gradient_variables(q, style):\n",
    "    trainable_variables = {}\n",
    "    if style == \"Single\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [[], []]\n",
    "    elif style == \"Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [[], []]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [[], []]\n",
    "    elif style == \"Controlled-Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [0, 0]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [[], []]\n",
    "                trainable_variables[str(i) + \"--\" + str(i + 1)] = [[], []]\n",
    "    return trainable_variables\n",
    "\n",
    "\n",
    "def get_probabilities(circ, count=10000, inducing=False):\n",
    "    if inducing == True:\n",
    "        count *= 10\n",
    "    job = execute(circ, backend, shots=count)\n",
    "    results = job.result().get_counts(circ)\n",
    "    try:\n",
    "        prob = results['0'] / (results['1'] + results['0'])\n",
    "        prob = (prob - 0.5)\n",
    "        if prob <= 0:\n",
    "            prob = 1e-16\n",
    "        else:\n",
    "            prob = prob * 2\n",
    "    except:\n",
    "        prob = 1\n",
    "    return prob\n",
    "\n",
    "\n",
    "\n",
    "# Define loss function. SWAP Test returns probability, so minmax probability is logical\n",
    "def cost_function(p, yreal):\n",
    "    if yreal == 1:\n",
    "        return -np.log(p)\n",
    "    else:\n",
    "        return -np.log(1 - p)\n",
    "\n",
    "\n",
    "def update_weights(init_value, lr, grad):\n",
    "    while lr * grad > 2 * np.pi:\n",
    "        lr /= 10\n",
    "        print(\"Warning - Gradient taking steps that are very large. Drop learning rate\")\n",
    "    weight_update = lr * grad\n",
    "    new_value = init_value\n",
    "    if new_value - weight_update > 2 * np.pi:\n",
    "        new_value = (new_value - weight_update) - 2 * np.pi\n",
    "    elif new_value - weight_update < 0:\n",
    "        new_value = (new_value - weight_update) + 2 * np.pi\n",
    "    else:\n",
    "        new_value = new_value - weight_update\n",
    "    return new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55421af-fa1d-49c1-87bc-a828506b5e9d",
   "metadata": {},
   "source": [
    "### <font color='green'> Encode Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35910da-c633-4605-acda-a87b8e3f83a4",
   "metadata": {},
   "source": [
    "<font color='green'>Fully changed</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42086ed7-f926-405c-9937-d964101d7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_circuit(circ_ident, num_qubits, values, qubit_start=1, qubit_end=5):\n",
    "    #normalize the vector \n",
    "    values_sq = np.square(values)\n",
    "    norm = np.linalg.norm(values_sq)\n",
    "    values_norm = values_sq / norm\n",
    "\n",
    "    #print(values_norm, values_norm[0]**2 + values_norm[1]**2 + values_norm[2]**2 + values_norm[3]**2) \n",
    "    \n",
    "    #create a matrix where the first column has the data\n",
    "    mat = np.zeros((len(values_norm),len(values_norm)))\n",
    "    mat[:,0] = values_norm\n",
    "\n",
    "    #get the unitary matrix through singular value decomposition\n",
    "    u, s, v = scipy.linalg.svd(mat)\n",
    "    instruction = UnitaryGate(u)\n",
    "\n",
    "    # print(u)\n",
    "    \n",
    "    #append the instruction to the circuit (last 2 qubits)\n",
    "    circ_ident.append(instruction,[3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1195f8-6c5b-4e76-beae-f6e544908baf",
   "metadata": {},
   "source": [
    "#### Discriminator Training Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e39a798e-8454-430b-8fa3-dccbe3c03235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# We treat the first n qubits are the discriminators state. n is always defined as the\n",
    "# integer division floor of the qubit count.\n",
    "# This is due to the fact that a state will always be k qubits, therefore the\n",
    "# number of total qubits must be 2k+1. 2k as we need k for the disc, and k to represent\n",
    "# either the other learned quantum state, or k to represent a data point\n",
    "# then +1 to perform the SWAP test. Therefore, we know that we will always end up\n",
    "# with an odd number of qubits. We take the floor to solve for k. 1st k represents\n",
    "# disc, 2nd k represents the \"loaded\" state be it gen or real data\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Use different function calls to represent training a GENERATOR or training a DISCRIMINATOR\n",
    "# ------------------------------------------------------------------------------------\n",
    "def disc_real_training_circuit(training_variables, data, key=None, key_value=None, diff=False, fwd_diff=False):\n",
    "    circ = QuantumCircuit(q, c)\n",
    "    circ.h(0)\n",
    "    if diff == True and fwd_diff == True:\n",
    "        training_variables[key][key_value] += par_shift\n",
    "    if diff == True and fwd_diff == False:\n",
    "        training_variables[key][key_value] -= par_shift\n",
    "    traditional_learning_layer(circ, q, training_variables, style=layer_style, qubit_start=1, qubit_end=q // 2 + 1)\n",
    "    data_loading_circuit(circ, q, data, qubit_start=q // 2 + 1, qubit_end=q)  \n",
    "    swap_test(circ, q)\n",
    "    if diff == True and fwd_diff == True:\n",
    "        training_variables[key][key_value] -= par_shift\n",
    "    if diff == True and fwd_diff == False:\n",
    "        training_variables[key][key_value] += par_shift\n",
    "    return circ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be03d2-e3a4-4bc9-a51f-9e5d1b5db8f2",
   "metadata": {},
   "source": [
    "#### Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "786c6109-aef7-4c2f-b52e-2903ebdcc404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "--------------------\n",
      "train_var_0 training\n",
      "Time for Epoch 1 is 13.442872047424316 sec\n",
      "--------------------\n",
      "Time for Epoch 2 is 13.328546047210693 sec\n",
      "--------------------\n",
      "Time for Epoch 3 is 13.46542501449585 sec\n",
      "--------------------\n",
      "Time for Epoch 4 is 13.237547874450684 sec\n",
      "--------------------\n",
      "Time for Epoch 5 is 13.060286045074463 sec\n",
      "--------------------\n",
      "Time for Epoch 6 is 13.113777875900269 sec\n",
      "--------------------\n",
      "Time for Epoch 7 is 13.05539083480835 sec\n",
      "--------------------\n",
      "Time for Epoch 8 is 13.073254108428955 sec\n",
      "--------------------\n",
      "Time for Epoch 9 is 13.030282974243164 sec\n",
      "--------------------\n",
      "Time for Epoch 10 is 12.942445755004883 sec\n",
      "--------------------\n",
      "Time for Epoch 11 is 13.056267976760864 sec\n",
      "--------------------\n",
      "Time for Epoch 12 is 13.027143001556396 sec\n",
      "--------------------\n",
      "Time for Epoch 13 is 12.968090772628784 sec\n",
      "--------------------\n",
      "Time for Epoch 14 is 13.047589778900146 sec\n",
      "--------------------\n",
      "Time for Epoch 15 is 13.074322938919067 sec\n",
      "--------------------\n",
      "Time for Epoch 16 is 13.033631324768066 sec\n",
      "--------------------\n",
      "Time for Epoch 17 is 13.493293046951294 sec\n",
      "--------------------\n",
      "Time for Epoch 18 is 12.9203040599823 sec\n",
      "--------------------\n",
      "Time for Epoch 19 is 13.054363250732422 sec\n",
      "--------------------\n",
      "Time for Epoch 20 is 13.035937070846558 sec\n",
      "--------------------\n",
      "Time for Epoch 21 is 12.969534158706665 sec\n",
      "--------------------\n",
      "Time for Epoch 22 is 13.018227815628052 sec\n",
      "--------------------\n",
      "Time for Epoch 23 is 13.03170108795166 sec\n",
      "--------------------\n",
      "Time for Epoch 24 is 12.960753917694092 sec\n",
      "--------------------\n",
      "Time for Epoch 25 is 13.043207883834839 sec\n",
      "--------------------\n",
      "Time for Epoch 1 is 13.538697957992554 sec\n",
      "--------------------\n",
      "Time for Epoch 2 is 13.429928064346313 sec\n",
      "--------------------\n",
      "Time for Epoch 3 is 13.472457885742188 sec\n",
      "--------------------\n",
      "Time for Epoch 4 is 13.392991065979004 sec\n",
      "--------------------\n",
      "Time for Epoch 5 is 13.73147177696228 sec\n",
      "--------------------\n",
      "Time for Epoch 6 is 13.543450117111206 sec\n",
      "--------------------\n",
      "Time for Epoch 7 is 13.234448671340942 sec\n",
      "--------------------\n",
      "Time for Epoch 8 is 13.366704940795898 sec\n",
      "--------------------\n",
      "Time for Epoch 9 is 13.306175947189331 sec\n",
      "--------------------\n",
      "Time for Epoch 10 is 13.338773727416992 sec\n",
      "--------------------\n",
      "Time for Epoch 11 is 13.277432918548584 sec\n",
      "--------------------\n",
      "Time for Epoch 12 is 13.31037187576294 sec\n",
      "--------------------\n",
      "Time for Epoch 13 is 13.401862144470215 sec\n",
      "--------------------\n",
      "Time for Epoch 14 is 13.327147960662842 sec\n",
      "--------------------\n",
      "Time for Epoch 15 is 13.197291851043701 sec\n",
      "--------------------\n",
      "Time for Epoch 16 is 13.299057960510254 sec\n",
      "--------------------\n",
      "Time for Epoch 17 is 13.381259202957153 sec\n",
      "--------------------\n",
      "Time for Epoch 18 is 13.296830892562866 sec\n",
      "--------------------\n",
      "Time for Epoch 19 is 13.368054866790771 sec\n",
      "--------------------\n",
      "Time for Epoch 20 is 13.215762853622437 sec\n",
      "--------------------\n",
      "Time for Epoch 21 is 13.311143159866333 sec\n",
      "--------------------\n",
      "Time for Epoch 22 is 13.377933740615845 sec\n",
      "--------------------\n",
      "Time for Epoch 23 is 13.229259967803955 sec\n",
      "--------------------\n",
      "Time for Epoch 24 is 13.324177026748657 sec\n",
      "--------------------\n",
      "Time for Epoch 25 is 13.306999921798706 sec\n",
      "--------------------\n",
      "Ones predicted 115 Zeros predicted 72\n",
      "Accuracy 0.8342245989304813\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------------\n",
    "# THIS SECTION WE DO THE TUNING FOR WHAT WE KNOW WE WANT TO BE CHANGING!\n",
    "# ------------------------------------------------------------------------------------------\n",
    "\n",
    "q = 5  # Number of qubits = Dimensionality of data = round up to even number = num qubits\n",
    "c = 1\n",
    "circ = QuantumCircuit(q, c)\n",
    "circ.h(0)\n",
    "layer_style = \"Dual\"\n",
    "train_var_0 = init_random_variables(q // 2, layer_style)\n",
    "train_var_1 = init_random_variables(q // 2, layer_style)\n",
    "train_var_2 = init_random_variables(q // 2, layer_style)\n",
    "\n",
    "tracked_d_loss = []\n",
    "tracked_d_loss1 = []\n",
    "tracked_d_loss2 = []\n",
    "gradients = []\n",
    "learning_rate = 0.01\n",
    "train_iter = 25\n",
    "corr = 0\n",
    "wrong = 0\n",
    "loss_d_to_real = 0\n",
    "print('Starting Training')\n",
    "print('-' * 20)\n",
    "print(\"train_var_0 training\")\n",
    "for epoch in range(train_iter):\n",
    "    start = time.time()\n",
    "    loss = [0, 0]\n",
    "    par_shift = 0.5 * np.pi / ((1 + epoch) ** 0.5)\n",
    "    for index, point in enumerate(pca_data_rot3):\n",
    "        for key, value in train_var_0.items():\n",
    "            if str(q // 2 + 1) in key:\n",
    "                break\n",
    "            for key_value in range(len(value)):\n",
    "                forward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_0, point, key, key_value, diff=True, fwd_diff=True)))\n",
    "                backward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_0, point, key, key_value, diff=True, fwd_diff=False)))\n",
    "                df = 0.5 * (forward_diff - backward_diff)\n",
    "                train_var_0[key][key_value] -= df * learning_rate\n",
    "    print('Time for Epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "    print(\"-\" * 20)\n",
    "    save_variables(train_var_0, epoch, 3)\n",
    "\n",
    "for epoch in range(train_iter):\n",
    "    start = time.time()\n",
    "    loss = [0, 0]\n",
    "    par_shift = 0.5 * np.pi / ((1 + epoch) ** 0.5)\n",
    "    for index, point in enumerate(pca_data_rot6):\n",
    "        for key, value in train_var_1.items():\n",
    "            if str(q // 2 + 1) in key:\n",
    "                break\n",
    "            for key_value in range(len(value)):\n",
    "                forward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_1, point, key, key_value, diff=True, fwd_diff=True)))\n",
    "                backward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_1, point, key, key_value, diff=True, fwd_diff=False)))\n",
    "                df = 0.5 * (forward_diff - backward_diff)\n",
    "                train_var_1[key][key_value] -= df * learning_rate\n",
    "    print('Time for Epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "    print(\"-\" * 20)\n",
    "    save_variables(train_var_1, epoch, 6)\n",
    "\n",
    "#CHANGE PCA_DATA_ROT VARS HERE\n",
    "pca_data = []\n",
    "[pca_data.append(x) for x in pca_data_rot3]\n",
    "[pca_data.append(x) for x in pca_data_rot6]\n",
    "labels = []\n",
    "[labels.append(0) for _ in range(len(pca_data_rot3))]\n",
    "[labels.append(1) for _ in range(len(pca_data_rot6))]\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "ones = []\n",
    "zeros = []\n",
    "layer_style = 'Dual'\n",
    "\n",
    "ones_predicted = 0\n",
    "zeros_predicted = 0\n",
    "\n",
    "for index, x in enumerate(pca_data):\n",
    "    p0 = get_probabilities(disc_real_training_circuit(train_var_0, x, None, None, diff=False, fwd_diff=False))\n",
    "    p1 = get_probabilities(disc_real_training_circuit(train_var_1, x, None, None, diff=False, fwd_diff=False))\n",
    "    tp = p0 + p1\n",
    "    p0 = p0 / tp\n",
    "    p1 = p1 / tp\n",
    "    probs = np.array([p0, p1])\n",
    "    if np.argmax(probs) == labels[index]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "\n",
    "    if np.argmax(probs) == 1:\n",
    "        ones_predicted += 1\n",
    "    else:\n",
    "        zeros_predicted += 1\n",
    "\n",
    "print(\"Ones predicted\", ones_predicted, \"Zeros predicted\", zeros_predicted)\n",
    "print(f\"Accuracy {correct / (correct + wrong)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab9352ae-4eb0-412a-8188-38eaa7dca7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">         ┌───┐                                                ┌──────────┐   »\n",
       "q_0: ────┤ H ├────────────────────────────────────────────────┤0         ├─■─»\n",
       "     ┌───┴───┴────┐┌────────────┐┌───────────────┐            │  Unitary │ │ »\n",
       "q_1: ┤ Ry(5.9475) ├┤ Rz(6.6585) ├┤0              ├─■──────────┤1         ├─X─»\n",
       "     ├────────────┤├────────────┤│  Ryy(0.97228) │ │ZZ(2.011) └──────────┘ │ »\n",
       "q_2: ┤ Ry(1.1227) ├┤ Rz(1.6971) ├┤1              ├─■───────────────────────┼─»\n",
       "     └────────────┘└────────────┘└───────────────┘                         │ »\n",
       "q_3: ──────────────────────────────────────────────────────────────────────X─»\n",
       "                                                                             »\n",
       "q_4: ────────────────────────────────────────────────────────────────────────»\n",
       "                                                                             »\n",
       "c: 1/════════════════════════════════════════════════════════════════════════»\n",
       "                                                                             »\n",
       "«        ┌───┐┌─┐\n",
       "«q_0: ─■─┤ H ├┤M├\n",
       "«      │ └───┘└╥┘\n",
       "«q_1: ─┼───────╫─\n",
       "«      │       ║ \n",
       "«q_2: ─X───────╫─\n",
       "«      │       ║ \n",
       "«q_3: ─┼───────╫─\n",
       "«      │       ║ \n",
       "«q_4: ─X───────╫─\n",
       "«              ║ \n",
       "«c: 1/═════════╩═\n",
       "«              0 </pre>"
      ],
      "text/plain": [
       "         ┌───┐                                                ┌──────────┐   »\n",
       "q_0: ────┤ H ├────────────────────────────────────────────────┤0         ├─■─»\n",
       "     ┌───┴───┴────┐┌────────────┐┌───────────────┐            │  Unitary │ │ »\n",
       "q_1: ┤ Ry(5.9475) ├┤ Rz(6.6585) ├┤0              ├─■──────────┤1         ├─X─»\n",
       "     ├────────────┤├────────────┤│  Ryy(0.97228) │ │ZZ(2.011) └──────────┘ │ »\n",
       "q_2: ┤ Ry(1.1227) ├┤ Rz(1.6971) ├┤1              ├─■───────────────────────┼─»\n",
       "     └────────────┘└────────────┘└───────────────┘                         │ »\n",
       "q_3: ──────────────────────────────────────────────────────────────────────X─»\n",
       "                                                                             »\n",
       "q_4: ────────────────────────────────────────────────────────────────────────»\n",
       "                                                                             »\n",
       "c: 1/════════════════════════════════════════════════════════════════════════»\n",
       "                                                                             »\n",
       "«        ┌───┐┌─┐\n",
       "«q_0: ─■─┤ H ├┤M├\n",
       "«      │ └───┘└╥┘\n",
       "«q_1: ─┼───────╫─\n",
       "«      │       ║ \n",
       "«q_2: ─X───────╫─\n",
       "«      │       ║ \n",
       "«q_3: ─┼───────╫─\n",
       "«      │       ║ \n",
       "«q_4: ─X───────╫─\n",
       "«              ║ \n",
       "«c: 1/═════════╩═\n",
       "«              0 "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_real_training_circuit(train_var_1, point, key, key_value, diff=True, fwd_diff=True).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d75ac-1b96-4935-bb4b-b3e7abb041ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
