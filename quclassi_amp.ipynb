{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3275f0-77fb-4b5d-83fc-0ab62e99b762",
   "metadata": {},
   "source": [
    "#### Section 1: Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0d8db246-15b6-4254-af4b-b796c13d2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from qiskit import QuantumRegister, ClassicalRegister\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit import Aer, execute\n",
    "from math import pi,log\n",
    "from qiskit import *\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from qiskit import Aer, IBMQ\n",
    "import os\n",
    "from datetime import datetime\n",
    "from qiskit.extensions import UnitaryGate\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347631a-5ad7-4d1f-b8aa-cf54c64f51aa",
   "metadata": {},
   "source": [
    "#### Section 2: Running and Saving Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0fe356ce-9551-4092-8cfc-e65c5d462377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network saving and loading\n",
    "epoch = 25\n",
    "runtime_name = datetime.now().strftime(\"Date-%d%m%y--Hours-%H%M\")\n",
    "runtime_name += \"-epoch-{}\".format(epoch)\n",
    "os.mkdir(runtime_name)\n",
    "backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7272c0a-cb8a-4145-8c1c-a5dc86eb99a7",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "df9fde07-43d9-41bc-bdf7-d8c4b3ffe6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample to SUBSAMPLE datapoints. This is due to computational cost.\n",
    "# Chance SUBSAMPLE to what best suits your computer, to make a reasonable training time.\n",
    "test_images,test_labels = tf.keras.datasets.mnist.load_data()\n",
    "train_images = test_images[0].reshape(60000,784)\n",
    "train_labels = test_images[1]\n",
    "labels = test_images[1]\n",
    "train_images = train_images/255\n",
    "k=4\n",
    "pca = PCA(n_components=k)\n",
    "pca.fit(train_images)\n",
    "\n",
    "# Computational cost is high for 60,000 data points. Change 6000 to what your system can handle\n",
    "SUBSAMPLE = 1000\n",
    "pca_data = pca.transform(train_images)[:SUBSAMPLE]\n",
    "train_labels = train_labels[:SUBSAMPLE]\n",
    "t_pca_data = pca_data.copy()\n",
    "pca_descaler = [[] for _ in range(k)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce180a4-aba3-4a32-94aa-b9263de290d4",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0308c017-b195-464c-b00f-f53b830e1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation Section\n",
    "for i in range(k):\n",
    "    if pca_data[:,i].min() < 0:\n",
    "        pca_descaler[i].append(pca_data[:,i].min())\n",
    "        pca_data[:,i] += np.abs(pca_data[:,i].min())\n",
    "    else:\n",
    "        pca_descaler[i].append(pca_data[:,i].min())\n",
    "        pca_data[:,i] -= pca_data[:,i].min()\n",
    "    pca_descaler[i].append(pca_data[:,i].max())\n",
    "    pca_data[:,i] /= pca_data[:,i].max()\n",
    "\n",
    "pca_data_rot= np.sqrt(pca_data)\n",
    "\n",
    "valid_labels = None\n",
    "valid_labels = train_labels==3\n",
    "valid_labels += train_labels == 6\n",
    "\n",
    "for col in range(pca_data.shape[1]):\n",
    "    t_data_mean = pca_data[:,col].mean()\n",
    "    t_data_std = pca_data[:,col].std()\n",
    "    valid_upper_bound = pca_data[:,col] < t_data_mean+t_data_std\n",
    "    valid_lower_bound = pca_data[:,col] > t_data_mean-t_data_std\n",
    "    valid = np.logical_and(valid_upper_bound,valid_lower_bound)\n",
    "    pca_data = pca_data[valid]\n",
    "\n",
    "pca_data_rot3 = pca_data_rot[train_labels==3]\n",
    "pca_data_rot6 = pca_data_rot[train_labels==6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece1d78-92d2-43f6-8e0d-6562bfe3703e",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e1b70284-5cea-46d7-af48-3d007413f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointing code\n",
    "def save_variables(var_dict, epoch, number_class):\n",
    "    with open(f\"{runtime_name}/Epoch-{epoch}-Variables-numbers-{number_class}\", 'w') as file:\n",
    "        file.write(str(var_dict))\n",
    "\n",
    "# Ran_ang returns a random angle\n",
    "def ran_ang():\n",
    "    return np.random.rand() * 2 * np.pi\n",
    "\n",
    "\n",
    "def single_qubit_unitary(circ_ident, qubit_index, values):\n",
    "    circ_ident.ry(values[0], qubit_index)\n",
    "    circ_ident.rz(values[1], qubit_index)\n",
    "\n",
    "\n",
    "def dual_qubit_unitary(circ_ident, qubit_1, qubit_2, values):\n",
    "    circ_ident.ryy(values[0], qubit_1, qubit_2)\n",
    "    circ_ident.rzz(values[1], qubit_1, qubit_2)\n",
    "\n",
    "\n",
    "def controlled_dual_qubit_unitary(circ_ident, control_qubit, act_qubit, values):\n",
    "    circ_ident.cry(values[0], control_qubit, act_qubit)\n",
    "    circ_ident.crz(values[1], control_qubit, act_qubit)\n",
    "\n",
    "\n",
    "def traditional_learning_layer(circ_ident, num_qubits, values, style=\"Dual\", qubit_start=1, qubit_end=5):\n",
    "    if style == \"Dual\":\n",
    "        for qub in np.arange(qubit_start, qubit_end):\n",
    "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
    "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
    "            dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \",\" + str(qub + 1)])\n",
    "    elif style == \"Single\":\n",
    "        for qub in np.arange(qubit_start, qubit_end):\n",
    "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
    "    elif style == \"Controlled-Dual\":\n",
    "        for qub in np.arange(qubit_start, qubit_end):\n",
    "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
    "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
    "            dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \",\" + str(qub + 1)])\n",
    "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
    "            controlled_dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \"--\" + str(qub + 1)])\n",
    "\n",
    "\n",
    "def swap_test(circ_ident, num_qubits):\n",
    "    num_swap = num_qubits // 2\n",
    "    for i in range(num_swap):\n",
    "        circ_ident.cswap(0, i + 1, i + num_swap + 1)\n",
    "    circ_ident.h(0)\n",
    "    circ_ident.measure(0, 0)\n",
    "\n",
    "\n",
    "def init_random_variables(q, style):\n",
    "    trainable_variables = {}\n",
    "    if style == \"Single\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
    "    elif style == \"Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
    "    elif style == \"Controlled-Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
    "                trainable_variables[str(i) + \"--\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
    "    return trainable_variables\n",
    "\n",
    "\n",
    "def init_gradient_variables(q, style):\n",
    "    trainable_variables = {}\n",
    "    if style == \"Single\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [[], []]\n",
    "    elif style == \"Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [[], []]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [[], []]\n",
    "    elif style == \"Controlled-Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [0, 0]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [[], []]\n",
    "                trainable_variables[str(i) + \"--\" + str(i + 1)] = [[], []]\n",
    "    return trainable_variables\n",
    "\n",
    "\n",
    "def get_probabilities(circ, count=10000, inducing=False):\n",
    "    if inducing == True:\n",
    "        count *= 10\n",
    "    job = execute(circ, backend, shots=count)\n",
    "    results = job.result().get_counts(circ)\n",
    "    try:\n",
    "        prob = results['0'] / (results['1'] + results['0'])\n",
    "        prob = (prob - 0.5)\n",
    "        if prob <= 0:\n",
    "            prob = 1e-16\n",
    "        else:\n",
    "            prob = prob * 2\n",
    "    except:\n",
    "        prob = 1\n",
    "    return prob\n",
    "\n",
    "\n",
    "\n",
    "# Define loss function. SWAP Test returns probability, so minmax probability is logical\n",
    "def cost_function(p, yreal):\n",
    "    if yreal == 1:\n",
    "        return -np.log(p)\n",
    "    else:\n",
    "        return -np.log(1 - p)\n",
    "\n",
    "\n",
    "def update_weights(init_value, lr, grad):\n",
    "    while lr * grad > 2 * np.pi:\n",
    "        lr /= 10\n",
    "        print(\"Warning - Gradient taking steps that are very large. Drop learning rate\")\n",
    "    weight_update = lr * grad\n",
    "    new_value = init_value\n",
    "    if new_value - weight_update > 2 * np.pi:\n",
    "        new_value = (new_value - weight_update) - 2 * np.pi\n",
    "    elif new_value - weight_update < 0:\n",
    "        new_value = (new_value - weight_update) + 2 * np.pi\n",
    "    else:\n",
    "        new_value = new_value - weight_update\n",
    "    return new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55421af-fa1d-49c1-87bc-a828506b5e9d",
   "metadata": {},
   "source": [
    "### Encode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "42086ed7-f926-405c-9937-d964101d7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_circuit(circ_ident, num_qubits, values, qubit_start=1, qubit_end=5):\n",
    "    #create a matrix where the first column has the data\n",
    "    mat = np.zeros((len(values),len(values)))\n",
    "    mat[:,0] = values\n",
    "\n",
    "    #get the unitary matrix through singular value decomposition\n",
    "    u, s, v = scipy.linalg.svd(mat)\n",
    "    instruction = UnitaryGate(u)\n",
    "    \n",
    "    #append the instruction to the circuit\n",
    "    circ_ident.append(instruction,[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1195f8-6c5b-4e76-beae-f6e544908baf",
   "metadata": {},
   "source": [
    "#### Discriminator Training Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e39a798e-8454-430b-8fa3-dccbe3c03235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# We treat the first n qubits are the discriminators state. n is always defined as the\n",
    "# integer division floor of the qubit count.\n",
    "# This is due to the fact that a state will always be k qubits, therefore the\n",
    "# number of total qubits must be 2k+1. 2k as we need k for the disc, and k to represent\n",
    "# either the other learned quantum state, or k to represent a data point\n",
    "# then +1 to perform the SWAP test. Therefore, we know that we will always end up\n",
    "# with an odd number of qubits. We take the floor to solve for k. 1st k represents\n",
    "# disc, 2nd k represents the \"loaded\" state be it gen or real data\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Use different function calls to represent training a GENERATOR or training a DISCRIMINATOR\n",
    "# ------------------------------------------------------------------------------------\n",
    "def disc_real_training_circuit(training_variables, data, key=None, key_value=None, diff=False, fwd_diff=False):\n",
    "    circ = QuantumCircuit(q, c)\n",
    "    circ.h(0)\n",
    "    if diff == True and fwd_diff == True:\n",
    "        training_variables[key][key_value] += par_shift\n",
    "    if diff == True and fwd_diff == False:\n",
    "        training_variables[key][key_value] -= par_shift\n",
    "    traditional_learning_layer(circ, q, training_variables, style=layer_style, qubit_start=1, qubit_end=q // 2 + 1)\n",
    "    data_loading_circuit(circ, q, data, qubit_start=q // 2 + 1, qubit_end=q)  \n",
    "    swap_test(circ, q)\n",
    "    if diff == True and fwd_diff == True:\n",
    "        training_variables[key][key_value] -= par_shift\n",
    "    if diff == True and fwd_diff == False:\n",
    "        training_variables[key][key_value] += par_shift\n",
    "    return circ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be03d2-e3a4-4bc9-a51f-9e5d1b5db8f2",
   "metadata": {},
   "source": [
    "#### Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "786c6109-aef7-4c2f-b52e-2903ebdcc404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "--------------------\n",
      "train_var_0 training\n",
      "Time for Epoch 1 is 12.766915082931519 sec\n",
      "--------------------\n",
      "Time for Epoch 2 is 12.774670839309692 sec\n",
      "--------------------\n",
      "Time for Epoch 3 is 12.641342878341675 sec\n",
      "--------------------\n",
      "Time for Epoch 4 is 12.788464069366455 sec\n",
      "--------------------\n",
      "Time for Epoch 5 is 12.615712881088257 sec\n",
      "--------------------\n",
      "Time for Epoch 6 is 12.731959104537964 sec\n",
      "--------------------\n",
      "Time for Epoch 7 is 12.717814683914185 sec\n",
      "--------------------\n",
      "Time for Epoch 8 is 12.640975952148438 sec\n",
      "--------------------\n",
      "Time for Epoch 9 is 12.837967872619629 sec\n",
      "--------------------\n",
      "Time for Epoch 10 is 12.72655200958252 sec\n",
      "--------------------\n",
      "Time for Epoch 11 is 12.64073896408081 sec\n",
      "--------------------\n",
      "Time for Epoch 12 is 12.723104000091553 sec\n",
      "--------------------\n",
      "Time for Epoch 13 is 12.727550029754639 sec\n",
      "--------------------\n",
      "Time for Epoch 14 is 12.62237000465393 sec\n",
      "--------------------\n",
      "Time for Epoch 15 is 12.696265935897827 sec\n",
      "--------------------\n",
      "Time for Epoch 16 is 12.727941036224365 sec\n",
      "--------------------\n",
      "Time for Epoch 17 is 12.608885049819946 sec\n",
      "--------------------\n",
      "Time for Epoch 18 is 12.716646909713745 sec\n",
      "--------------------\n",
      "Time for Epoch 19 is 12.596537113189697 sec\n",
      "--------------------\n",
      "Time for Epoch 20 is 12.716357946395874 sec\n",
      "--------------------\n",
      "Time for Epoch 21 is 12.633924722671509 sec\n",
      "--------------------\n",
      "Time for Epoch 22 is 12.698040008544922 sec\n",
      "--------------------\n",
      "Time for Epoch 23 is 12.72749400138855 sec\n",
      "--------------------\n",
      "Time for Epoch 24 is 12.61184310913086 sec\n",
      "--------------------\n",
      "Time for Epoch 25 is 12.717597961425781 sec\n",
      "--------------------\n",
      "Time for Epoch 1 is 12.912236213684082 sec\n",
      "--------------------\n",
      "Time for Epoch 2 is 12.793230056762695 sec\n",
      "--------------------\n",
      "Time for Epoch 3 is 12.871989965438843 sec\n",
      "--------------------\n",
      "Time for Epoch 4 is 12.898104190826416 sec\n",
      "--------------------\n",
      "Time for Epoch 5 is 12.786584854125977 sec\n",
      "--------------------\n",
      "Time for Epoch 6 is 12.902235984802246 sec\n",
      "--------------------\n",
      "Time for Epoch 7 is 12.866713762283325 sec\n",
      "--------------------\n",
      "Time for Epoch 8 is 12.807940244674683 sec\n",
      "--------------------\n",
      "Time for Epoch 9 is 12.908782720565796 sec\n",
      "--------------------\n",
      "Time for Epoch 10 is 12.865996837615967 sec\n",
      "--------------------\n",
      "Time for Epoch 11 is 12.74760890007019 sec\n",
      "--------------------\n",
      "Time for Epoch 12 is 12.86416220664978 sec\n",
      "--------------------\n",
      "Time for Epoch 13 is 12.730566263198853 sec\n",
      "--------------------\n",
      "Time for Epoch 14 is 12.860196113586426 sec\n",
      "--------------------\n",
      "Time for Epoch 15 is 12.762954950332642 sec\n",
      "--------------------\n",
      "Time for Epoch 16 is 12.851197957992554 sec\n",
      "--------------------\n",
      "Time for Epoch 17 is 12.846628904342651 sec\n",
      "--------------------\n",
      "Time for Epoch 18 is 12.748913764953613 sec\n",
      "--------------------\n",
      "Time for Epoch 19 is 12.855306148529053 sec\n",
      "--------------------\n",
      "Time for Epoch 20 is 12.841457843780518 sec\n",
      "--------------------\n",
      "Time for Epoch 21 is 12.788629055023193 sec\n",
      "--------------------\n",
      "Time for Epoch 22 is 12.859508991241455 sec\n",
      "--------------------\n",
      "Time for Epoch 23 is 12.857265949249268 sec\n",
      "--------------------\n",
      "Time for Epoch 24 is 12.773758888244629 sec\n",
      "--------------------\n",
      "Time for Epoch 25 is 12.901525974273682 sec\n",
      "--------------------\n",
      "Accuracy 0.6524064171122995\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------------\n",
    "# THIS SECTION WE DO THE TUNING FOR WHAT WE KNOW WE WANT TO BE CHANGING!\n",
    "# ------------------------------------------------------------------------------------------\n",
    "\n",
    "q = 5  # Number of qubits = Dimensionality of data = round up to even number = num qubits\n",
    "c = 1\n",
    "circ = QuantumCircuit(q, c)\n",
    "circ.h(0)\n",
    "layer_style = \"Dual\"\n",
    "train_var_0 = init_random_variables(q // 2, layer_style)\n",
    "train_var_1 = init_random_variables(q // 2, layer_style)\n",
    "train_var_2 = init_random_variables(q // 2, layer_style)\n",
    "\n",
    "tracked_d_loss = []\n",
    "tracked_d_loss1 = []\n",
    "tracked_d_loss2 = []\n",
    "gradients = []\n",
    "learning_rate = 0.01\n",
    "train_iter = 25\n",
    "corr = 0\n",
    "wrong = 0\n",
    "loss_d_to_real = 0\n",
    "print('Starting Training')\n",
    "print('-' * 20)\n",
    "print(\"train_var_0 training\")\n",
    "for epoch in range(train_iter):\n",
    "    start = time.time()\n",
    "    loss = [0, 0]\n",
    "    par_shift = 0.5 * np.pi / ((1 + epoch) ** 0.5)\n",
    "    for index, point in enumerate(pca_data_rot3):\n",
    "        for key, value in train_var_0.items():\n",
    "            if str(q // 2 + 1) in key:\n",
    "                break\n",
    "            for key_value in range(len(value)):\n",
    "                forward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_0, point, key, key_value, diff=True, fwd_diff=True)))\n",
    "                backward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_0, point, key, key_value, diff=True, fwd_diff=False)))\n",
    "                df = 0.5 * (forward_diff - backward_diff)\n",
    "                train_var_0[key][key_value] -= df * learning_rate\n",
    "    print('Time for Epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "    print(\"-\" * 20)\n",
    "    save_variables(train_var_0, epoch, 3)\n",
    "\n",
    "for epoch in range(train_iter):\n",
    "    start = time.time()\n",
    "    loss = [0, 0]\n",
    "    par_shift = 0.5 * np.pi / ((1 + epoch) ** 0.5)\n",
    "    for index, point in enumerate(pca_data_rot6):\n",
    "        for key, value in train_var_1.items():\n",
    "            if str(q // 2 + 1) in key:\n",
    "                break\n",
    "            for key_value in range(len(value)):\n",
    "                forward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_1, point, key, key_value, diff=True, fwd_diff=True)))\n",
    "                backward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_1, point, key, key_value, diff=True, fwd_diff=False)))\n",
    "                df = 0.5 * (forward_diff - backward_diff)\n",
    "                train_var_1[key][key_value] -= df * learning_rate\n",
    "    print('Time for Epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "    print(\"-\" * 20)\n",
    "    save_variables(train_var_1, epoch, 6)\n",
    "\n",
    "#CHANGE PCA_DATA_ROT VARS HERE\n",
    "pca_data = []\n",
    "[pca_data.append(x) for x in pca_data_rot3]\n",
    "[pca_data.append(x) for x in pca_data_rot6]\n",
    "labels = []\n",
    "[labels.append(0) for _ in range(len(pca_data_rot3))]\n",
    "[labels.append(1) for _ in range(len(pca_data_rot6))]\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "ones = []\n",
    "zeros = []\n",
    "layer_style = 'Dual'\n",
    "for index, x in enumerate(pca_data):\n",
    "    p0 = get_probabilities(disc_real_training_circuit(train_var_0, x, None, None, diff=False, fwd_diff=False))\n",
    "    p1 = get_probabilities(disc_real_training_circuit(train_var_1, x, None, None, diff=False, fwd_diff=False))\n",
    "    tp = p0 + p1\n",
    "    p0 = p0 / tp\n",
    "    p1 = p1 / tp\n",
    "    probs = np.array([p0, p1])\n",
    "    if np.argmax(probs) == labels[index]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "\n",
    "print(f\"Accuracy {correct / (correct + wrong)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
