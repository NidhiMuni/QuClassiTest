{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3275f0-77fb-4b5d-83fc-0ab62e99b762",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0d8db246-15b6-4254-af4b-b796c13d2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from qiskit import QuantumRegister, ClassicalRegister\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit import Aer, execute\n",
    "from math import pi,log\n",
    "from qiskit import *\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from qiskit import Aer, IBMQ\n",
    "import os\n",
    "from datetime import datetime\n",
    "from qiskit.extensions import UnitaryGate\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347631a-5ad7-4d1f-b8aa-cf54c64f51aa",
   "metadata": {},
   "source": [
    "#### Running and Saving Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0fe356ce-9551-4092-8cfc-e65c5d462377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network saving and loading\n",
    "epoch = 25\n",
    "runtime_name = datetime.now().strftime(\"Date-%d%m%y--Hours-%H%M\")\n",
    "runtime_name += \"-epoch-{}\".format(epoch)\n",
    "os.mkdir(runtime_name)\n",
    "backend = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7272c0a-cb8a-4145-8c1c-a5dc86eb99a7",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "df9fde07-43d9-41bc-bdf7-d8c4b3ffe6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample to SUBSAMPLE datapoints. This is due to computational cost.\n",
    "# Chance SUBSAMPLE to what best suits your computer, to make a reasonable training time.\n",
    "test_images,test_labels = tf.keras.datasets.mnist.load_data()\n",
    "train_images = test_images[0].reshape(60000,784)\n",
    "train_labels = test_images[1]\n",
    "labels = test_images[1]\n",
    "train_images = train_images/255\n",
    "k=1\n",
    "pca = PCA(n_components=k)\n",
    "pca.fit(train_images)\n",
    "\n",
    "# Computational cost is high for 60,000 data points. Change 6000 to what your system can handle\n",
    "SUBSAMPLE = 1000\n",
    "pca_data = pca.transform(train_images)[:SUBSAMPLE]\n",
    "train_labels = train_labels[:SUBSAMPLE]\n",
    "t_pca_data = pca_data.copy()\n",
    "pca_descaler = [[] for _ in range(k)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce180a4-aba3-4a32-94aa-b9263de290d4",
   "metadata": {},
   "source": [
    "### <font color='green'>Data Transformation</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72407bc-bbf5-47f2-aaa5-116c8031ee7b",
   "metadata": {},
   "source": [
    "<font color='green'>Changes made: scale data to be between 0 and 15</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0308c017-b195-464c-b00f-f53b830e1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation Section\n",
    "for i in range(k):\n",
    "    if pca_data[:,i].min() < 0:\n",
    "        pca_descaler[i].append(pca_data[:,i].min())\n",
    "        pca_data[:,i] += np.abs(pca_data[:,i].min())\n",
    "    else:\n",
    "        pca_descaler[i].append(pca_data[:,i].min())\n",
    "        pca_data[:,i] -= pca_data[:,i].min()\n",
    "    pca_descaler[i].append(pca_data[:,i].max())\n",
    "    pca_data[:,i] /= pca_data[:,i].max()\n",
    "\n",
    "#CHANGE\n",
    "#going to use 4 bits per component, so scale each column between 0 and 15 (4 bits)\n",
    "pca_data_rot= np.round(pca_data * 15).astype(int)\n",
    "\n",
    "valid_labels = None\n",
    "valid_labels = train_labels==3\n",
    "valid_labels += train_labels == 6\n",
    "\n",
    "for col in range(pca_data.shape[1]):\n",
    "    t_data_mean = pca_data[:,col].mean()\n",
    "    t_data_std = pca_data[:,col].std()\n",
    "    valid_upper_bound = pca_data[:,col] < t_data_mean+t_data_std\n",
    "    valid_lower_bound = pca_data[:,col] > t_data_mean-t_data_std\n",
    "    valid = np.logical_and(valid_upper_bound,valid_lower_bound)\n",
    "    pca_data = pca_data[valid]\n",
    "\n",
    "pca_data_rot3 = pca_data_rot[train_labels==3]\n",
    "pca_data_rot6 = pca_data_rot[train_labels==6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fece1d78-92d2-43f6-8e0d-6562bfe3703e",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1b70284-5cea-46d7-af48-3d007413f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpointing code\n",
    "def save_variables(var_dict, epoch, number_class):\n",
    "    with open(f\"{runtime_name}/Epoch-{epoch}-Variables-numbers-{number_class}\", 'w') as file:\n",
    "        file.write(str(var_dict))\n",
    "\n",
    "# Ran_ang returns a random angle\n",
    "def ran_ang():\n",
    "    return np.random.rand() * 2 * np.pi\n",
    "\n",
    "\n",
    "def single_qubit_unitary(circ_ident, qubit_index, values):\n",
    "    circ_ident.ry(values[0], qubit_index)\n",
    "    circ_ident.rz(values[1], qubit_index)\n",
    "\n",
    "\n",
    "def dual_qubit_unitary(circ_ident, qubit_1, qubit_2, values):\n",
    "    circ_ident.ryy(values[0], qubit_1, qubit_2)\n",
    "    circ_ident.rzz(values[1], qubit_1, qubit_2)\n",
    "\n",
    "\n",
    "def controlled_dual_qubit_unitary(circ_ident, control_qubit, act_qubit, values):\n",
    "    circ_ident.cry(values[0], control_qubit, act_qubit)\n",
    "    circ_ident.crz(values[1], control_qubit, act_qubit)\n",
    "\n",
    "\n",
    "def traditional_learning_layer(circ_ident, num_qubits, values, style=\"Dual\", qubit_start=1, qubit_end=5):\n",
    "    if style == \"Dual\":\n",
    "        for qub in np.arange(qubit_start, qubit_end):\n",
    "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
    "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
    "            dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \",\" + str(qub + 1)])\n",
    "    elif style == \"Single\":\n",
    "        for qub in np.arange(qubit_start, qubit_end):\n",
    "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
    "    elif style == \"Controlled-Dual\":\n",
    "        for qub in np.arange(qubit_start, qubit_end):\n",
    "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
    "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
    "            dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \",\" + str(qub + 1)])\n",
    "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
    "            controlled_dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \"--\" + str(qub + 1)])\n",
    "\n",
    "\n",
    "def swap_test(circ_ident, num_qubits):\n",
    "    num_swap = num_qubits // 2\n",
    "    for i in range(num_swap):\n",
    "        circ_ident.cswap(0, i + 1, i + num_swap + 1)\n",
    "    circ_ident.h(0)\n",
    "    circ_ident.measure(0, 0)\n",
    "\n",
    "\n",
    "def init_random_variables(q, style):\n",
    "    trainable_variables = {}\n",
    "    if style == \"Single\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
    "    elif style == \"Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
    "    elif style == \"Controlled-Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
    "                trainable_variables[str(i) + \"--\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
    "    return trainable_variables\n",
    "\n",
    "\n",
    "def init_gradient_variables(q, style):\n",
    "    trainable_variables = {}\n",
    "    if style == \"Single\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [[], []]\n",
    "    elif style == \"Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [[], []]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [[], []]\n",
    "    elif style == \"Controlled-Dual\":\n",
    "        for i in np.arange(1, q + 1):\n",
    "            trainable_variables[str(i)] = [0, 0]\n",
    "            if i != q:\n",
    "                trainable_variables[str(i) + \",\" + str(i + 1)] = [[], []]\n",
    "                trainable_variables[str(i) + \"--\" + str(i + 1)] = [[], []]\n",
    "    return trainable_variables\n",
    "\n",
    "\n",
    "def get_probabilities(circ, count=10000, inducing=False):\n",
    "    if inducing == True:\n",
    "        count *= 10\n",
    "    job = execute(circ, backend, shots=count)\n",
    "    results = job.result().get_counts(circ)\n",
    "    try:\n",
    "        prob = results['0'] / (results['1'] + results['0'])\n",
    "        prob = (prob - 0.5)\n",
    "        if prob <= 0:\n",
    "            prob = 1e-16\n",
    "        else:\n",
    "            prob = prob * 2\n",
    "    except:\n",
    "        prob = 1\n",
    "    return prob\n",
    "\n",
    "\n",
    "\n",
    "# Define loss function. SWAP Test returns probability, so minmax probability is logical\n",
    "def cost_function(p, yreal):\n",
    "    if yreal == 1:\n",
    "        return -np.log(p)\n",
    "    else:\n",
    "        return -np.log(1 - p)\n",
    "\n",
    "\n",
    "def update_weights(init_value, lr, grad):\n",
    "    while lr * grad > 2 * np.pi:\n",
    "        lr /= 10\n",
    "        print(\"Warning - Gradient taking steps that are very large. Drop learning rate\")\n",
    "    weight_update = lr * grad\n",
    "    new_value = init_value\n",
    "    if new_value - weight_update > 2 * np.pi:\n",
    "        new_value = (new_value - weight_update) - 2 * np.pi\n",
    "    elif new_value - weight_update < 0:\n",
    "        new_value = (new_value - weight_update) + 2 * np.pi\n",
    "    else:\n",
    "        new_value = new_value - weight_update\n",
    "    return new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55421af-fa1d-49c1-87bc-a828506b5e9d",
   "metadata": {},
   "source": [
    "### <font color='green'> Encode Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9a74d-4f46-4655-8e8e-42ef2bbcf14b",
   "metadata": {},
   "source": [
    "<font color='green'>Fully changed</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "42086ed7-f926-405c-9937-d964101d7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading_circuit(circ_ident, num_qubits, values, qubit_start=1, qubit_end=5):\n",
    "    #will receive 1 number between 0 and 15\n",
    "    for index,a in enumerate(bin(21).split('b')[-1]):\n",
    "        if a == '1':\n",
    "            circ_ident.x(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1195f8-6c5b-4e76-beae-f6e544908baf",
   "metadata": {},
   "source": [
    "#### Discriminator Training Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e39a798e-8454-430b-8fa3-dccbe3c03235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# We treat the first n qubits are the discriminators state. n is always defined as the\n",
    "# integer division floor of the qubit count.\n",
    "# This is due to the fact that a state will always be k qubits, therefore the\n",
    "# number of total qubits must be 2k+1. 2k as we need k for the disc, and k to represent\n",
    "# either the other learned quantum state, or k to represent a data point\n",
    "# then +1 to perform the SWAP test. Therefore, we know that we will always end up\n",
    "# with an odd number of qubits. We take the floor to solve for k. 1st k represents\n",
    "# disc, 2nd k represents the \"loaded\" state be it gen or real data\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Use different function calls to represent training a GENERATOR or training a DISCRIMINATOR\n",
    "# ------------------------------------------------------------------------------------\n",
    "def disc_real_training_circuit(training_variables, data, key=None, key_value=None, diff=False, fwd_diff=False):\n",
    "    circ = QuantumCircuit(q, c)\n",
    "    circ.h(0)\n",
    "    if diff == True and fwd_diff == True:\n",
    "        training_variables[key][key_value] += par_shift\n",
    "    if diff == True and fwd_diff == False:\n",
    "        training_variables[key][key_value] -= par_shift\n",
    "    traditional_learning_layer(circ, q, training_variables, style=layer_style, qubit_start=1, qubit_end=q // 2 + 1)\n",
    "    data_loading_circuit(circ, q, data, qubit_start=q // 2 + 1, qubit_end=q)  \n",
    "    swap_test(circ, q)\n",
    "    if diff == True and fwd_diff == True:\n",
    "        training_variables[key][key_value] -= par_shift\n",
    "    if diff == True and fwd_diff == False:\n",
    "        training_variables[key][key_value] += par_shift\n",
    "    return circ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be03d2-e3a4-4bc9-a51f-9e5d1b5db8f2",
   "metadata": {},
   "source": [
    "#### Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "786c6109-aef7-4c2f-b52e-2903ebdcc404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "--------------------\n",
      "train_var_0 training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key_value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(value)):\n\u001b[1;32m     35\u001b[0m     forward_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(get_probabilities(\n\u001b[1;32m     36\u001b[0m         disc_real_training_circuit(train_var_0, point, key, key_value, diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fwd_diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)))\n\u001b[0;32m---> 37\u001b[0m     backward_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(get_probabilities(\n\u001b[1;32m     38\u001b[0m         disc_real_training_circuit(train_var_0, point, key, key_value, diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fwd_diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)))\n\u001b[1;32m     39\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (forward_diff \u001b[38;5;241m-\u001b[39m backward_diff)\n\u001b[1;32m     40\u001b[0m     train_var_0[key][key_value] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m df \u001b[38;5;241m*\u001b[39m learning_rate\n",
      "Cell \u001b[0;32mIn[99], line 93\u001b[0m, in \u001b[0;36mget_probabilities\u001b[0;34m(circ, count, inducing)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inducing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     count \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 93\u001b[0m job \u001b[38;5;241m=\u001b[39m execute(circ, backend, shots\u001b[38;5;241m=\u001b[39mcount)\n\u001b[1;32m     94\u001b[0m results \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mget_counts(circ)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/qiskit/execute_function.py:286\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(experiments, backend, basis_gates, coupling_map, backend_properties, initial_layout, seed_transpiler, optimization_level, pass_manager, shots, memory, seed_simulator, default_qubit_los, default_meas_los, qubit_lo_range, meas_lo_range, schedule_los, meas_level, meas_return, memory_slots, memory_slot_size, rep_time, rep_delay, parameter_binds, schedule_circuit, inst_map, meas_map, scheduling_method, init_qubits, **run_config)\u001b[0m\n\u001b[1;32m    283\u001b[0m     experiments \u001b[38;5;241m=\u001b[39m pass_manager\u001b[38;5;241m.\u001b[39mrun(experiments)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# transpiling the circuits using given transpile options\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     experiments \u001b[38;5;241m=\u001b[39m transpile(\n\u001b[1;32m    287\u001b[0m         experiments,\n\u001b[1;32m    288\u001b[0m         basis_gates\u001b[38;5;241m=\u001b[39mbasis_gates,\n\u001b[1;32m    289\u001b[0m         coupling_map\u001b[38;5;241m=\u001b[39mcoupling_map,\n\u001b[1;32m    290\u001b[0m         backend_properties\u001b[38;5;241m=\u001b[39mbackend_properties,\n\u001b[1;32m    291\u001b[0m         initial_layout\u001b[38;5;241m=\u001b[39minitial_layout,\n\u001b[1;32m    292\u001b[0m         seed_transpiler\u001b[38;5;241m=\u001b[39mseed_transpiler,\n\u001b[1;32m    293\u001b[0m         optimization_level\u001b[38;5;241m=\u001b[39moptimization_level,\n\u001b[1;32m    294\u001b[0m         backend\u001b[38;5;241m=\u001b[39mbackend,\n\u001b[1;32m    295\u001b[0m     )\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schedule_circuit:\n\u001b[1;32m    298\u001b[0m     experiments \u001b[38;5;241m=\u001b[39m schedule(\n\u001b[1;32m    299\u001b[0m         circuits\u001b[38;5;241m=\u001b[39mexperiments,\n\u001b[1;32m    300\u001b[0m         backend\u001b[38;5;241m=\u001b[39mbackend,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m         method\u001b[38;5;241m=\u001b[39mscheduling_method,\n\u001b[1;32m    304\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/qiskit/compiler/transpiler.py:337\u001b[0m, in \u001b[0;36mtranspile\u001b[0;34m(circuits, backend, basis_gates, inst_map, coupling_map, backend_properties, initial_layout, layout_method, routing_method, translation_method, scheduling_method, instruction_durations, dt, approximation_degree, timing_constraints, seed_transpiler, optimization_level, callback, output_name, unitary_synthesis_method, unitary_synthesis_plugin_config, target, hls_config, init_method, optimization_method, ignore_backend_supplied_default_methods)\u001b[0m\n\u001b[1;32m    333\u001b[0m inst_map \u001b[38;5;241m=\u001b[39m _parse_inst_map(inst_map, backend)\n\u001b[1;32m    335\u001b[0m _check_circuits_coupling_map(circuits, coupling_map, backend)\n\u001b[0;32m--> 337\u001b[0m timing_constraints \u001b[38;5;241m=\u001b[39m _parse_timing_constraints(backend, timing_constraints)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _given_inst_map \u001b[38;5;129;01mand\u001b[39;00m inst_map\u001b[38;5;241m.\u001b[39mhas_custom_gate() \u001b[38;5;129;01mand\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;66;03m# Do not mutate backend target\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     target \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(target)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/qiskit/compiler/transpiler.py:612\u001b[0m, in \u001b[0;36m_parse_timing_constraints\u001b[0;34m(backend, timing_constraints)\u001b[0m\n\u001b[1;32m    610\u001b[0m         timing_constraints \u001b[38;5;241m=\u001b[39m TimingConstraints(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtiming_constraints)\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 612\u001b[0m         timing_constraints \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39mtiming_constraints()\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m timing_constraints\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/qiskit_aer/backends/aerbackend.py:348\u001b[0m, in \u001b[0;36mAerBackend.target\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target\n\u001b[0;32m--> 348\u001b[0m tgt \u001b[38;5;241m=\u001b[39m convert_to_target(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfiguration(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties(), \u001b[38;5;28;01mNone\u001b[39;00m, NAME_MAPPING)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coupling_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     tgt\u001b[38;5;241m.\u001b[39m_coupling_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coupling_map\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/qiskit/providers/backend_compat.py:184\u001b[0m, in \u001b[0;36mconvert_to_target\u001b[0;34m(configuration, properties, defaults, custom_name_mapping, add_delay, filter_faulty)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m target:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m name_mapping:\n\u001b[0;32m--> 184\u001b[0m         target\u001b[38;5;241m.\u001b[39madd_instruction(name_mapping[op], name\u001b[38;5;241m=\u001b[39mop)\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m QiskitError(\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not have a known mapping. Use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_name_mapping to map this name to an Operation object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/qiskit/transpiler/target.py:426\u001b[0m, in \u001b[0;36mTarget.add_instruction\u001b[0;34m(self, instruction, properties, name)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m properties:\n\u001b[0;32m--> 426\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_global_operations[instruction\u001b[38;5;241m.\u001b[39mnum_qubits]\u001b[38;5;241m.\u001b[39madd(instruction_name)\n\u001b[1;32m    427\u001b[0m     qargs_val \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m qarg \u001b[38;5;129;01min\u001b[39;00m properties:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/qiskit/circuit/instruction.py:637\u001b[0m, in \u001b[0;36mInstruction.num_qubits\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set the name.\"\"\"\u001b[39;00m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m--> 637\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnum_qubits\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the number of qubits.\"\"\"\u001b[39;00m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_qubits\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------------\n",
    "# THIS SECTION WE DO THE TUNING FOR WHAT WE KNOW WE WANT TO BE CHANGING!\n",
    "# ------------------------------------------------------------------------------------------\n",
    "\n",
    "q = 5  # Number of qubits = Dimensionality of data = round up to even number = num qubits\n",
    "c = 1\n",
    "circ = QuantumCircuit(q, c)\n",
    "circ.h(0)\n",
    "layer_style = \"Dual\"\n",
    "train_var_0 = init_random_variables(q // 2, layer_style)\n",
    "train_var_1 = init_random_variables(q // 2, layer_style)\n",
    "train_var_2 = init_random_variables(q // 2, layer_style)\n",
    "\n",
    "tracked_d_loss = []\n",
    "tracked_d_loss1 = []\n",
    "tracked_d_loss2 = []\n",
    "gradients = []\n",
    "learning_rate = 0.01\n",
    "train_iter = 25\n",
    "corr = 0\n",
    "wrong = 0\n",
    "loss_d_to_real = 0\n",
    "print('Starting Training')\n",
    "print('-' * 20)\n",
    "print(\"train_var_0 training\")\n",
    "for epoch in range(train_iter):\n",
    "    start = time.time()\n",
    "    loss = [0, 0]\n",
    "    par_shift = 0.5 * np.pi / ((1 + epoch) ** 0.5)\n",
    "    for index, point in enumerate(pca_data_rot3):\n",
    "        for key, value in train_var_0.items():\n",
    "            if str(q // 2 + 1) in key:\n",
    "                break\n",
    "            for key_value in range(len(value)):\n",
    "                forward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_0, point, key, key_value, diff=True, fwd_diff=True)))\n",
    "                backward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_0, point, key, key_value, diff=True, fwd_diff=False)))\n",
    "                df = 0.5 * (forward_diff - backward_diff)\n",
    "                train_var_0[key][key_value] -= df * learning_rate\n",
    "    print('Time for Epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "    print(\"-\" * 20)\n",
    "    save_variables(train_var_0, epoch, 3)\n",
    "\n",
    "for epoch in range(train_iter):\n",
    "    start = time.time()\n",
    "    loss = [0, 0]\n",
    "    par_shift = 0.5 * np.pi / ((1 + epoch) ** 0.5)\n",
    "    for index, point in enumerate(pca_data_rot6):\n",
    "        for key, value in train_var_1.items():\n",
    "            if str(q // 2 + 1) in key:\n",
    "                break\n",
    "            for key_value in range(len(value)):\n",
    "                forward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_1, point, key, key_value, diff=True, fwd_diff=True)))\n",
    "                backward_diff = -np.log(get_probabilities(\n",
    "                    disc_real_training_circuit(train_var_1, point, key, key_value, diff=True, fwd_diff=False)))\n",
    "                df = 0.5 * (forward_diff - backward_diff)\n",
    "                train_var_1[key][key_value] -= df * learning_rate\n",
    "    print('Time for Epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "    print(\"-\" * 20)\n",
    "    save_variables(train_var_1, epoch, 6)\n",
    "\n",
    "#CHANGE PCA_DATA_ROT VARS HERE\n",
    "pca_data = []\n",
    "[pca_data.append(x) for x in pca_data_rot3]\n",
    "[pca_data.append(x) for x in pca_data_rot6]\n",
    "labels = []\n",
    "[labels.append(0) for _ in range(len(pca_data_rot3))]\n",
    "[labels.append(1) for _ in range(len(pca_data_rot6))]\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "ones = []\n",
    "zeros = []\n",
    "layer_style = 'Dual'\n",
    "\n",
    "ones_predicted = 0\n",
    "zeros_predicted = 0\n",
    "\n",
    "for index, x in enumerate(pca_data):\n",
    "    p0 = get_probabilities(disc_real_training_circuit(train_var_0, x, None, None, diff=False, fwd_diff=False))\n",
    "    p1 = get_probabilities(disc_real_training_circuit(train_var_1, x, None, None, diff=False, fwd_diff=False))\n",
    "    tp = p0 + p1\n",
    "    p0 = p0 / tp\n",
    "    p1 = p1 / tp\n",
    "    probs = np.array([p0, p1])\n",
    "    if np.argmax(probs) == labels[index]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "\n",
    "    if np.argmax(probs) == 1:\n",
    "        ones_predicted += 1\n",
    "    else:\n",
    "        zeros_predicted += 1\n",
    "\n",
    "print(\"Ones predicted\", ones_predicted, \"Zeros predicted\", zeros_predicted)\n",
    "print(f\"Accuracy {correct / (correct + wrong)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9352ae-4eb0-412a-8188-38eaa7dca7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d75ac-1b96-4935-bb4b-b3e7abb041ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
